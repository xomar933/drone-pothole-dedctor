import json
import asyncio
import mavsdk
from mavsdk import System
from mavsdk.mission import MissionItem, MissionPlan
import cv2
import os
import datetime
from ultralytics import YOLO

# Load the trained YOLO model
# model = YOLO("YOLOv8n.pt")
model = YOLO("pothole.pt")


# --- Load mission from .plan file ---
def load_mission(file_path="mission.plan"):
    with open(file_path, "r") as file:
        plan_data = json.load(file)

    waypoints = []
    for item in plan_data["mission"]["items"]:
        command = item["command"]
        lat, lon, alt = item["params"][4], item["params"][5], item["params"][6]
        if command == 16:  # Waypoint
            waypoints.append((lat, lon, alt, command))
        elif command == 20:  # RETURN_TO_LAUNCH
            waypoints.append(("RETURN_TO_LAUNCH", command, lat, lon, alt))
        elif command == 21:  # Land
            waypoints.append(("LAND", command, lat, lon, alt))
        elif command == 22:  # Takeoff
            waypoints.append(("TAKEOFF", command, lat, lon, alt))

    return waypoints


# --- Create mission plan ---
async def setup_mission(drone, waypoints):
    mission_items = []

    for item in waypoints:
        print(item)
        if item[0] == "RETURN_TO_LAUNCH":
            _, _, lat, lon, alt = item
            # mission_items.append(MissionItem(
            #     lat, lon, alt, 5.0, True,
            #     float('nan'), float('nan'), MissionItem.CameraAction.NONE,
            #     float('nan'), float('nan'), float('nan'), float('nan'),
            #     float('nan'), MissionItem.VehicleAction.NONE
            # ))
        elif item[0] == "LAND":
            _, _, lat, lon, alt = item
            mission_items.append(MissionItem(
                lat, lon, alt, 5.0, True,
                float('nan'), float('nan'), MissionItem.CameraAction.NONE,
                float('nan'), float('nan'), float('nan'), float('nan'),
                float('nan'), MissionItem.VehicleAction.LAND
            ))
        elif item[0] == "TAKEOFF":
            _, _, lat, lon, alt = item
            mission_items.append(MissionItem(
                lat, lon, alt, 5.0, True,
                float('nan'), float('nan'), MissionItem.CameraAction.NONE,
                float('nan'), float('nan'), float('nan'), float('nan'),
                float('nan'), MissionItem.VehicleAction.TAKEOFF
            ))
        else:
            lat, lon, alt, _ = item
            mission_items.append(MissionItem(
                lat, lon, alt, 5.0, True,
                float('nan'), float('nan'), MissionItem.CameraAction.NONE,
                float('nan'), float('nan'), float('nan'), float('nan'),
                float('nan'), MissionItem.VehicleAction.NONE
            ))

    mission_plan = MissionPlan(mission_items)
    await drone.mission.set_return_to_launch_after_mission(True)
    print("ðŸ“¡ Uploading mission to the drone...")
    await drone.mission.upload_mission(mission_plan)
    await asyncio.sleep(5)  # Increased sleep to ensure mission upload is complete

    print("ðŸš€ Starting mission...")
    await drone.mission.start_mission()

    # Check mission status continuously
    async for mission_progress in drone.mission.mission_progress():
        print(f"Mission progress: {mission_progress.current}/{mission_progress.total}")
        if mission_progress.current == mission_progress.total:
            print("-- Mission completed!")
            break
        await asyncio.sleep(2)  # Sleep before checking again


# --- Process image using YOLOv8 ---
def analyze_image(image_path, lat, lon, save_path):
    results = model(image_path)
    detections = []

    # ðŸ‘‡ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù„Ù„Ø­ÙØ± Ø§Ù„Ù…ÙƒØªØ´ÙØ© Ø¯Ø§Ø®Ù„ save_path
    detections_path = f"{save_path}/detected_potholes"
    os.makedirs(detections_path, exist_ok=True)

    # ðŸ‘‡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ø±Ø³Ù… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¹Ù„ÙŠÙ‡Ø§
    img = cv2.imread(image_path)
    confidence_text = f""
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])  # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø©
            confidence = float(box.conf[0])
            label = model.names[int(box.cls[0])]
            print(f"ðŸ” {label} with confidence {confidence:.3f}")

            if confidence > 0.25:
                # ðŸ‘‡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
                detections.append({
                    "image": image_path,
                    "coordinates": {"latitude": lat, "longitude": lon},
                    "bbox": [x1, y1, x2, y2],
                    "confidence": confidence,
                    "label": label
                })

                # ðŸ–¼ï¸ Ø±Ø³Ù… Ø§Ù„Ø¨ÙˆÙƒØ³ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©
                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
                text = f"{label}: {confidence:.2f}"
                cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                confidence_text = f"Confidence: {confidence:.2f}"

    # ðŸ‘‡ Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ§Ø±ÙŠØ®ØŒ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª ÙˆØ§Ù„Ø«Ù‚Ø© Ø£Ø³ÙÙ„ Ø§Ù„ØµÙˆØ±Ø©

    date_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    coords_text = f"Lat: {lat:.6f}, Lon: {lon:.6f}"

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„
    bottom_text = f"Date: {date_time} | {coords_text} | {confidence_text}"

    # ðŸ‘‡ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù†Øµ ÙÙŠ Ø£Ø³ÙÙ„ Ø§Ù„ØµÙˆØ±Ø©
    cv2.putText(img, bottom_text, (10, img.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    cv2.imshow("Drone Live", img)
    # ðŸ‘‡ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø­ÙØ± ÙÙŠ Ù…Ø¬Ù„Ø¯ Ù…Ù†ÙØµÙ„
    if detections:
        json_path = f"{save_path}/detections.json"
        with open(json_path, "a") as json_file:
            json.dump(detections, json_file, indent=4)

        # ðŸ‘‡ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ detected_potholes
        new_img_path = f"{detections_path}/{os.path.basename(image_path)}"
        cv2.imwrite(new_img_path, img)  # âœ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„

        print(f"âœ… Pothole detected! Image saved in {new_img_path}")


# --- Record video and capture images continuously ---
async def record_video(drone):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"data/{timestamp}"  # Path to store frames
    os.makedirs(save_path, exist_ok=True)

    cap = cv2.VideoCapture("vid1.webm")
    if not cap.isOpened():
        print("âŒ Failed to open video file! Skipping video-related tasks.")
        return  # Skip video processing if the file cannot be opened

    frame_count = 0
    frame_skip = 5  # ðŸ‘ˆ Ø¹Ø¯Ø¯ Ø§Ù„ÙØ±ÙŠÙ…Ø§Øª Ø§Ù„ØªÙŠ Ø³Ù†ØªØ®Ø·Ø§Ù‡Ø§ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„

    # Continuously record and analyze frames from the video

    while True:
        ret, frame = cap.read()
        if not ret:
            break  # End of video

        # ðŸ‘‡ ØªØ­Ù„ÙŠÙ„ ÙØ±ÙŠÙ… ÙˆØ§Ø­Ø¯ ÙƒÙ„ frame_skip ÙØ±ÙŠÙ…Ø§Øª
        if frame_count % frame_skip == 0:
            # if True:
            img_path = f"{save_path}/frame_{frame_count}.jpg"
            cv2.imwrite(img_path, frame)
            print(f"ðŸ“¸ Image saved: {img_path}")

            # Get current position of the drone
            async for position in drone.telemetry.position():
                lat, lon = position.latitude_deg, position.longitude_deg
                break  # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ù‚ÙŠÙ…Ø© ÙÙ‚Ø· Ø«Ù… Ù†Ø®Ø±Ø¬ Ù…Ù† Ø§Ù„Ø­Ù„Ù‚Ø©

                frame = analyze_image_live(frame, lat, lon)  # ðŸ”¥ ØªØ­Ø¯ÙŠØ« Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¨Ø§Ø´Ø±Ø©

            # ðŸ‘‡ Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ ÙÙŠ Ù†Ø§ÙØ°Ø©

            # ðŸ‘‡ Ø®Ø±ÙˆØ¬ Ø¹Ù†Ø¯ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Q
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                # Analyze the image and detect potholes or issues
            # cv2.imshow("Drone Live", frame)
            analyze_image(img_path, lat, lon, save_path)

        frame_count += 1
        # await asyncio.sleep(1)  # Simulate real-time capture

    cap.release()


def analyze_image_live(frame, lat, lon):
    results = model(frame)

    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            confidence = float(box.conf[0])
            label = model.names[int(box.cls[0])]

            if confidence > 0.50:
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                text = f"{label}: {confidence:.2f}"
                cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                date_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                bottom_text = f"Date: {date_time} | Lat: {lat:.6f}, Lon: {lon:.6f}"
                cv2.putText(frame, bottom_text, (10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                            (255, 255, 255), 2)

    return frame


# --- Main function ---
async def main():
    waypoints = load_mission()
    drone = System()

    print("ðŸ”— Connecting to drone...")
    await drone.connect(system_address="udp://:14540")

    print("âœ… Waiting for drone connection...")
    async for state in drone.core.connection_state():
        if state.is_connected:
            print("âœ… Drone connected!")
            break

    print("âœ… Waiting for GPS readiness...")
    async for health in drone.telemetry.health():
        if health.is_global_position_ok and health.is_home_position_ok:
            print("âœ… GPS is ready!")
            break

    print("ðŸš€ Taking off...")
    # print(await drone.param.get_all_params())
    await drone.action.arm()
    # await drone.param.set_param_float("MIS_TAKEOFF_ALT", 2.5)
    await drone.action.takeoff()
    await asyncio.sleep(5)

    # Run the tasks asynchronously without waiting for camera
    await asyncio.gather(
        setup_mission(drone, waypoints),  # Continue mission setup and execution
        record_video(drone)  # Continue video recording and analysis (video from file)
    )


if __name__ == "__main__":
    asyncio.run(main())
